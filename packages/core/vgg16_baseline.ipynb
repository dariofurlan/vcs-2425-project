{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VmXnXRuu0yPY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from vcs2425 import ApplyColormap, ImageNetDepth\n",
    "\n",
    "\n",
    "# 1. Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# 2. Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "color_map_transform = ApplyColormap(cmap='viridis')\n",
    "\n",
    "# 3. Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    color_map_transform,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    color_map_transform,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ms2OxapHC4kX",
    "outputId": "81d7871c-a7b0-4415-db26-9d8889495325"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../ILSVRC2012_depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 4. Load full dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m data_dir = \u001b[33m'\u001b[39m\u001b[33m../ILSVRC2012_depth\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m full_dataset = \u001b[43mImageNetDepth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m class_to_idx = full_dataset.class_to_idx\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 5. Manual split\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/vcs-2425/packages/core/vcs2425/dataset.py:23\u001b[39m, in \u001b[36mImageNetDepth.__init__\u001b[39m\u001b[34m(self, root_dir, transform)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Pattern: ILSVRC2012_depth_[incremental]_[classname].png\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.pattern = re.compile(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mILSVRC2012_val_\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+_(.+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     24\u001b[39m     match = \u001b[38;5;28mself\u001b[39m.pattern.match(filename)\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m match:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../ILSVRC2012_depth'"
     ]
    }
   ],
   "source": [
    "# 4. Load full dataset\n",
    "data_dir = '../ILSVRC2012_depth'\n",
    "full_dataset = ImageNetDepth(root_dir=data_dir)\n",
    "class_to_idx = full_dataset.class_to_idx\n",
    "\n",
    "# 5. Manual split\n",
    "indices = list(range(len(full_dataset)))\n",
    "random.shuffle(indices)\n",
    "split = int(0.8 * len(full_dataset))\n",
    "train_indices, val_indices = indices[:split], indices[split:]\n",
    "\n",
    "# 6. Create separate train and val datasets with transforms\n",
    "train_base = ImageNetDepth(root_dir=data_dir, transform=train_transform)\n",
    "val_base = ImageNetDepth(root_dir=data_dir, transform=val_transform)\n",
    "train_base.class_to_idx = class_to_idx\n",
    "val_base.class_to_idx = class_to_idx\n",
    "\n",
    "train_dataset = Subset(train_base, train_indices)\n",
    "val_dataset = Subset(val_base, val_indices)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# 7. DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=True,  # Better memory management\n",
    "    persistent_workers=True  # Keep workers alive between iterations\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    # num_workers=4,\n",
    "    # pin_memory=True,  # Better memory management\n",
    "    # persistent_workers=True  # Keep workers alive between iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(prediction, ground_truth):\n",
    "    prediction = prediction.argmax(dim=1, keepdim=True)\n",
    "    correct = prediction.eq(ground_truth.view_as(prediction)).sum()\n",
    "    accuracy = correct.float() / ground_truth.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(images)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = calculate_accuracy(predictions, labels)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += acc.item()\n",
    "\n",
    "    train_accuracy = epoch_accuracy / len(loader)\n",
    "    train_loss = epoch_loss / len(loader)\n",
    "    \n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_accuracy = 0.0\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Evaluation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            predictions = model(images)\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = calculate_accuracy(predictions, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += acc.item()\n",
    "\n",
    "\n",
    "    return epoch_loss / len(loader), epoch_accuracy / len(loader)\n",
    "\n",
    "def evaluate_topk(model, loader, k=5):\n",
    "    model.eval()\n",
    "    topk_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=f\"Top-{k} Evaluation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            predictions = model(images)\n",
    "            _, topk_preds = predictions.topk(k, dim=1)\n",
    "            topk_correct = topk_preds.eq(labels.view(-1, 1).expand_as(topk_preds)).sum().item()\n",
    "            topk_accuracy += topk_correct / labels.size(0)\n",
    "\n",
    "    return topk_accuracy / len(loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating \"as-is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import f\n",
    "\n",
    "top_1s = []\n",
    "top_5s = []\n",
    "\n",
    "colormaps = ['stacked', 'gray', 'viridis', 'plasma', 'magma', 'Spectral']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for cmap in tqdm(colormaps, desc=\"Evaluating on different colormaps\"):\n",
    "    color_map_transform.cmap = cmap\n",
    "\n",
    "    top_1 = evaluate_topk(model, val_loader, k=1)\n",
    "    top_5 = evaluate_topk(model, val_loader, k=5)\n",
    "    \n",
    "    top_1s.append(top_1)\n",
    "    top_5s.append(top_5)\n",
    "    \n",
    "    print(f\"Colormap: {cmap}, Top-1 Accuracy: {top_1:.4f}, Top-5 Accuracy: {top_5:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure for the grid\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Set up bar width and positions\n",
    "x = np.arange(len(colormaps))\n",
    "width = 0.35\n",
    "\n",
    "# Create bars\n",
    "rects1 = ax.bar(x - width/2, top_1s, width, label='Top-1 Accuracy')\n",
    "rects2 = ax.bar(x + width/2, top_5s, width, label='Top-5 Accuracy')\n",
    "\n",
    "# Add labels, title and legend\n",
    "ax.set_xlabel('Colormap')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Top-1 and Top-5 Accuracies by Colormap')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(colormaps)\n",
    "ax.legend()\n",
    "\n",
    "# Add text labels on top of bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vcs-2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
