

@article{AIPrivacyElderCare,
  author         = {Wang, Chang-Yueh and Lin, Fang-Suey},
  title          = {AI-Driven Privacy in Elderly Care: Developing a Comprehensive Solution for Camera-Based Monitoring of Older Adults},
  journal        = {Applied Sciences},
  volume         = {14},
  year           = {2024},
  number         = {10},
  article-number = {4150},
  url            = {https://www.mdpi.com/2076-3417/14/10/4150},
  issn           = {2076-3417},
  abstract       = {The need for privacy in elderly care is crucial, especially where constant monitoring can intrude on personal dignity. This research introduces the development of a unique camera-based monitoring system designed to address the dual objectives of elderly care: privacy and safety. At its core, the system employs an AI-driven technique for real-time subject anonymization. Unlike traditional methods such as pixelization or blurring, our proposed approach effectively removes the subject under monitoring from the scene, replacing them with a two-dimensional avatar. This is achieved through the use of YOLOv8, which facilitates accurate real-time person detection and pose estimation. Furthermore, the proposed system incorporates a fall detection algorithm that utilizes a residual causal convolutional network together with motion features of persons to identify emergency situations and promptly notify caregivers in the event of a fall. The effectiveness of the system is evaluated to emphasize its advanced privacy protection technique and fall detection capabilities using several metrics. This evaluation demonstrates the system’s proficiency in real-world applications and its potential to enhance both safety and privacy in elderly care environments.},
  doi            = {10.3390/app14104150}
}

@article{carlucci2018de2codeepdepth,
  author     = {Fabio Maria Carlucci and
                Paolo Russo and
                S. M. Baharlou and
                Barbara Caputo},
  title      = {(DE)\({}^{\mbox{2}}\) {CO:} Deep Depth Colorization},
  journal    = {CoRR},
  volume     = {abs/1703.10881},
  year       = {2017},
  url        = {http://arxiv.org/abs/1703.10881},
  eprinttype = {arXiv},
  eprint     = {1703.10881},
  timestamp  = {Wed, 26 Jan 2022 22:26:07 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/CarlucciRBC17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{ConvolutionBasedEncoding,
  author         = {Gopalapillai, Radhakrishnan and Gupta, Deepa and Zakariah, Mohammed and Alotaibi, Yousef Ajami},
  title          = {Convolution-Based Encoding of Depth Images for Transfer Learning in RGB-D Scene Classification},
  journal        = {Sensors},
  volume         = {21},
  year           = {2021},
  number         = {23},
  article-number = {7950},
  url            = {https://www.mdpi.com/1424-8220/21/23/7950},
  pubmedid       = {34883955},
  issn           = {1424-8220},
  abstract       = {Classification of indoor environments is a challenging problem. The availability of low-cost depth sensors has opened up a new research area of using depth information in addition to color image (RGB) data for scene understanding. Transfer learning of deep convolutional networks with pairs of RGB and depth (RGB-D) images has to deal with integrating these two modalities. Single-channel depth images are often converted to three-channel images by extracting horizontal disparity, height above ground, and the angle of the pixel’s local surface normal (HHA) to apply transfer learning using networks trained on the Places365 dataset. The high computational cost of HHA encoding can be a major disadvantage for the real-time prediction of scenes, although this may be less important during the training phase. We propose a new, computationally efficient encoding method that can be integrated with any convolutional neural network. We show that our encoding approach performs equally well or better in a multimodal transfer learning setup for scene classification. Our encoding is implemented in a customized and pretrained VGG16 Net. We address the class imbalance problem seen in the image dataset using a method based on the synthetic minority oversampling technique (SMOTE) at the feature level. With appropriate image augmentation and fine-tuning, our network achieves scene classification accuracy comparable to that of other state-of-the-art architectures.},
  doi            = {10.3390/s21237950}
}

@article{FruitClassificationDepthImages,
  title     = {Fruit Classification using Colorized Depth Images},
  journal   = {International Journal of Advanced Computer Science and Applications},
  doi       = {10.14569/IJACSA.2023.01405106},
  url       = {http://dx.doi.org/10.14569/IJACSA.2023.01405106},
  year      = {2023},
  publisher = {The Science and Information Organization},
  volume    = {14},
  number    = {5},
  author    = {Dhong Fhel K. Gom-os}
} 

@article{HumanPoseEstimationPrivacy,
  author     = {Vinkle Srivastav and
                Afshin Gangi and
                Nicolas Padoy},
  title      = {Human Pose Estimation on Privacy-Preserving Low-Resolution Depth Images},
  journal    = {CoRR},
  volume     = {abs/2007.08340},
  year       = {2020},
  url        = {https://arxiv.org/abs/2007.08340},
  eprinttype = {arXiv},
  eprint     = {2007.08340},
  timestamp  = {Wed, 22 Jul 2020 12:09:15 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2007-08340.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{imagenet,
  author  = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  title   = {{ImageNet Large Scale Visual Recognition Challenge}},
  year    = {2015},
  journal = {International Journal of Computer Vision (IJCV)},
  doi     = {10.1007/s11263-015-0816-y},
  volume  = {115},
  number  = {3},
  pages   = {211-252}
}

@article{inceptionv3,
  author     = {Christian Szegedy and
                Vincent Vanhoucke and
                Sergey Ioffe and
                Jonathon Shlens and
                Zbigniew Wojna},
  title      = {Rethinking the Inception Architecture for Computer Vision},
  journal    = {CoRR},
  volume     = {abs/1512.00567},
  year       = {2015},
  url        = {http://arxiv.org/abs/1512.00567},
  eprinttype = {arXiv},
  eprint     = {1512.00567},
  timestamp  = {Mon, 13 Aug 2018 16:49:07 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/SzegedyVISW15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{InHomeMonitoringDepthSensors,
  author         = {Momin, Md Sarfaraz and Sufian, Abu and Barman, Debaditya and Dutta, Paramartha and Dong, Mianxiong and Leo, Marco},
  title          = {In-Home Older Adults’ Activity Pattern Monitoring Using Depth Sensors: A Review},
  journal        = {Sensors},
  volume         = {22},
  year           = {2022},
  number         = {23},
  article-number = {9067},
  url            = {https://www.mdpi.com/1424-8220/22/23/9067},
  pubmedid       = {36501769},
  issn           = {1424-8220},
  abstract       = {The global population is aging due to many factors, including longer life expectancy through better healthcare, changing diet, physical activity, etc. We are also witnessing various frequent epidemics as well as pandemics. The existing healthcare system has failed to deliver the care and support needed to our older adults (seniors) during these frequent outbreaks. Sophisticated sensor-based in-home care systems may offer an effective solution to this global crisis. The monitoring system is the key component of any in-home care system. The evidence indicates that they are more useful when implemented in a non-intrusive manner through different visual and audio sensors. Artificial Intelligence (AI) and Computer Vision (CV) techniques may be ideal for this purpose. Since the RGB imagery-based CV technique may compromise privacy, people often hesitate to utilize in-home care systems which use this technology. Depth, thermal, and audio-based CV techniques could be meaningful substitutes here. Due to the need to monitor larger areas, this review article presents a systematic discussion on the state-of-the-art using depth sensors as primary data-capturing techniques. We mainly focused on fall detection and other health-related physical patterns. As gait parameters may help to detect these activities, we also considered depth sensor-based gait parameters separately. The article provides discussions on the topic in relation to the terminology, reviews, a survey of popular datasets, and future scopes.},
  doi            = {10.3390/s22239067}
}

@article{LearningPhaseMask,
  author  = {Zaid Tas and collaborators},
  title   = {Learning Phase Mask for Privacy-Preserving Passive Depth Estimation},
  journal = {PrivacyMask},
  year    = {2023},
  url     = {https://zaidtas.github.io/privacymask/pdf/privacy_preserving_depth_estimation.pdf}
}

@INPROCEEDINGS{washington-rgbd,

  author={Lai, Kevin and Bo, Liefeng and Ren, Xiaofeng and Fox, Dieter},

  booktitle={2011 IEEE International Conference on Robotics and Automation}, 

  title={A large-scale hierarchical multi-view RGB-D object dataset}, 

  year={2011},

  volume={},

  number={},

  pages={1817-1824},

  keywords={Cameras;Videos;Video sequences;Three dimensional displays;Visualization;Object recognition;Robot sensing systems},

  doi={10.1109/ICRA.2011.5980382}}


@misc{marigold,
  title         = {Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation},
  author        = {Bingxin Ke and Anton Obukhov and Shengyu Huang and Nando Metzger and Rodrigo Caye Daudt and Konrad Schindler},
  year          = {2024},
  eprint        = {2312.02145},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2312.02145}
}

@inproceedings{alexnet,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
  volume    = {25},
  year      = {2012}
}


@article{PrivacyPreservingActionRecognition,
  author     = {Edward Chou and
                Matthew Tan and
                Cherry Zou and
                Michelle Guo and
                Albert Haque and
                Arnold Milstein and
                Li Fei{-}Fei},
  title      = {Privacy-Preserving Action Recognition for Smart Hospitals using Low-Resolution
                Depth Images},
  journal    = {CoRR},
  volume     = {abs/1811.09950},
  year       = {2018},
  url        = {http://arxiv.org/abs/1811.09950},
  eprinttype = {arXiv},
  eprint     = {1811.09950},
  timestamp  = {Mon, 22 Jul 2019 14:55:31 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1811-09950.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{PrivacyPreservingConvMixer,
  author         = {Qi, Zheng and MaungMaung, AprilPyone and Kiya, Hitoshi},
  title          = {Privacy-Preserving Image Classification Using ConvMixer with Adaptative Permutation Matrix and Block-Wise Scrambled Image Encryption},
  journal        = {Journal of Imaging},
  volume         = {9},
  year           = {2023},
  number         = {4},
  article-number = {85},
  url            = {https://www.mdpi.com/2313-433X/9/4/85},
  pubmedid       = {37103236},
  issn           = {2313-433X},
  abstract       = {In this paper, we propose a privacy-preserving image classification method using block-wise scrambled images and a modified ConvMixer. Conventional block-wise scrambled encryption methods usually need the combined use of an adaptation network and a classifier to reduce the influence of image encryption. However, we point out that it is problematic to utilize large-size images with conventional methods using an adaptation network because of the significant increment in computation cost. Thus, we propose a novel privacy-preserving method that allows us not only to apply block-wise scrambled images to ConvMixer for both training and testing without an adaptation network, but also to provide a high classification accuracy and strong robustness against attack methods. Furthermore, we also evaluate the computation cost of state-of-the-art privacy-preserving DNNs to confirm that our proposed method requires fewer computational resources. In an experiment, we evaluated the classification performance of the proposed method on CIFAR-10 and ImageNet compared with other methods and the robustness against various ciphertext-only-attacks.},
  doi            = {10.3390/jimaging9040085}
}

@article{PrivacyPreservingVisionTransformer,
  author  = {Chris Black and Sarah Blue},
  title   = {Privacy-Preserving Vision Transformer on Permutation-Encrypted Images},
  journal = {OpenReview},
  year    = {2022},
  url     = {https://openreview.net/forum?id=eL1iX7DMnPI}
}

@article{rainbow_harmful,
  author         = {Chen, Leiyu and Li, Shaobo and Bai, Qiang and Yang, Jing and Jiang, Sanlong and Miao, Yanming},
  title          = {Review of Image Classification Algorithms Based on Convolutional Neural Networks},
  journal        = {Remote Sensing},
  volume         = {13},
  year           = {2021},
  number         = {22},
  article-number = {4712},
  url            = {https://www.mdpi.com/2072-4292/13/22/4712},
  issn           = {2072-4292},
  abstract       = {Image classification has always been a hot research direction in the world, and the emergence of deep learning has promoted the development of this field. Convolutional neural networks (CNNs) have gradually become the mainstream algorithm for image classification since 2012, and the CNN architecture applied to other visual recognition tasks (such as object detection, object localization, and semantic segmentation) is generally derived from the network architecture in image classification. In the wake of these successes, CNN-based methods have emerged in remote sensing image scene classification and achieved advanced classification accuracy. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art (SOAT) network architectures. Along the way, we analyze (1) the basic structure of artificial neural networks (ANNs) and the basic network layers of CNNs, (2) the classic predecessor network models, (3) the recent SOAT network algorithms, (4) comprehensive comparison of various image classification methods mentioned in this article. Finally, we have also summarized the main analysis and discussion in this article, as well as introduce some of the current trends.},
  doi            = {10.3390/rs13224712}
}



@article{resnet50,
  author     = {Kaiming He and
                Xiangyu Zhang and
                Shaoqing Ren and
                Jian Sun},
  title      = {Deep Residual Learning for Image Recognition},
  journal    = {CoRR},
  volume     = {abs/1512.03385},
  year       = {2015},
  url        = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint     = {1512.03385},
  timestamp  = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{RGBDObjectRecognition,
  author    = {Zia, Saman and Yüksel, Buket and Yüret, Deniz and Yemez, Yücel},
  booktitle = {2017 IEEE International Conference on Computer Vision Workshops (ICCVW)},
  title     = {RGB-D Object Recognition Using Deep Convolutional Neural Networks},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {887-894},
  keywords  = {Three-dimensional displays;Feature extraction;Object recognition;Two dimensional displays;Image color analysis},
  doi       = {10.1109/ICCVW.2017.109}
}

@article{SowPostureClassification,
  author  = {George Purple and collaborators},
  title   = {Classification of Sow Postures Using CNN and Depth Images},
  journal = {Biosystems Engineering},
  year    = {2023},
  url     = {https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1921&context=biosysengfacpub}
}

@article{vgg19,
  author  = {Karen Simonyan and Andrew Zisserman},
  title   = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal = {arXiv preprint arXiv:1409.1556},
  year    = {2014},
  url     = {https://arxiv.org/abs/1409.1556}
}