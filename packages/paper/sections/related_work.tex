\section{Related Work}
Recent research has increasingly focused on integrating computer vision with privacy-preserving techniques, especially in sensitive environments such as hospitals, nursing homes, and eldercare centers. Depth images have gained traction in the research community as a compelling privacy-aware alternative to conventional RGB images. They inherently lack fine-grained visual details—such as facial features or clothing patterns—while still capturing the spatial and structural cues necessary for recognition tasks. Studies such as \cite{PrivacyPreservingActionRecognition, HumanPoseEstimationPrivacy} have demonstrated the effectiveness of low-resolution or depth-only data across tasks such as action recognition, pose estimation, and fall detection, highlighting its potential in real-world healthcare and surveillance settings.

Encrypted image-based classification techniques, such as block-wise scrambling, permutation encryption, and homomorphic encryption, have been used to protect sensitive data during both training and inference \cite{PrivacyPreservingVisionTransformer, PrivacyPreservingConvMixer}. When combined with modern architectures like Vision Transformers or ConvMixers, these methods have been shown to effectively preserve privacy without compromising accuracy.

Hardware-based approaches have also been proposed to enforce privacy directly at the sensing stage. For example, optical filters like phase masks \cite{LearningPhaseMask} can limit facial detail capture, which allows privacy-preserving depth estimation at the point of image acquisition. Some approaches go further by anonymizing individuals in real time through avatars or abstract representations \cite{AIPrivacyElderCare}, addressing privacy concerns by system-level architecture rather than relying solely on data manipulation or model design.

Regarding the use of depth data for classification, several papers have proposed adaptations of models originally trained on RGB images. For example, lightweight encoders \cite{ConvolutionBasedEncoding} can take a single-channel depth input and transform it into a three-channel RGB-like input, thereby making it compatible with pre-trained CNNs such as VGG-16. Other methods augment VGG-16 with a single 3D convolution layer \cite{RGBDObjectRecognition} to enable depth-only inference without retraining on depth images. Similarly, applying simple color maps (e.g., Jet) to depth images allows standard models like ResNet-101 and ResNet-18 to achieve high classification accuracy in fruit sorting and animal posture recognition \cite{FruitClassificationDepthImages, SowPostureClassification}.

Depth-based methods have also proven effective in privacy-sensitive healthcare environments. Privacy-aware in-home monitoring systems using depth sensors for tasks like fall detection and gait analysis in eldercare \cite{InHomeMonitoringDepthSensors} offer a less privacy-invasive alternative to RGB-based solutions. Beyond human monitoring, depth data has been applied to classify animal postures \cite{SowPostureClassification}, illustrating the broader versatility of this modality where texture is unnecessary or unavailable.

Collectively, these studies reflect a growing consensus on the technical viability and societal urgency of privacy-preserving computer vision. However, many focus on specialized architectures, encrypted RGB inputs, or hardware solutions. By contrast, relatively few explore the baseline performance of classification models on raw depth images. In this paper, we address that gap by evaluating widely used image classification models (i.e., AlexNet \cite{alexnet}, VGG19 \cite{vgg19}, ResNet50 \cite{resnet50}, and Inception-v3 \cite{inceptionv3}) on depth images, providing a foundation for future privacy-preserving systems.
